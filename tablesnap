#!/usr/bin/env python
import pyinotify
import boto

from optparse import OptionParser
from traceback import format_exc
from threading import Thread
import logging
import os.path
import socket
import json
import sys
import os
import ConfigParser
import shlex


config = ConfigParser.RawConfigParser()
conf_paths = [os.getenv('TABLESNAP_CONF'),
              'tablesnap.conf',
              os.path.join(os.path.expanduser('~'), '.tablesnap.conf'),
              '/etc/tablesnap/tablesnap.conf']

for path in conf_paths:
    try:
        config.read(path)
        break
    except:
        pass

log = logging.getLogger('tablesnap')
stderr = logging.StreamHandler()
stderr.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))
log.addHandler(stderr)
log.setLevel(logging.DEBUG)


class UploadHandler(pyinotify.ProcessEvent):
    def my_init(self, bucket=None):
        self.bucket = bucket
        try:
            self.prefix = boto.utils.get_instance_metadata()['ami-launch-index']
        except:
            self.prefix = socket.getfqdn()

    def process_IN_MOVED_TO(self, event):
        if event.pathname.find('-tmp') == -1:
            keyname = '%s:%s' % (self.prefix, event.pathname)
            key = self.bucket.get_key(keyname)
            if key is None:
                t = Thread(target=self.upload_sstable, args=(
                           keyname, event.pathname))
                t.setDaemon(True)
                t.start()
            else:
                log.info("Keyname %s already exists, skipping upload" % keyname)

    def upload_sstable(self, keyname, filename, with_index=True):
        log.info('Uploading %s' % filename)

        def progress(sent, total):
            if sent == total:
                log.info('Finished uploading %s' % filename)

        try:
            dirname = os.path.dirname(filename)
            if with_index:
                key = self.bucket.new_key('%s-listdir.json' % keyname)
                key.set_contents_from_string(
                    json.dumps({dirname: os.listdir(dirname)}))

            key = self.bucket.new_key(keyname)
            key.set_contents_from_filename(filename, replace=False, cb=progress)
        except:
            log.error('Error uploading %s\n%s' % (keyname, format_exc()))


def backup_files(handler, bucket, paths):
    for path in paths:
        log.info('Backing up %s' % path)
        for filename in os.listdir(path):
            if filename.find('-tmp') != -1:
                continue
            keyname = '%s:%s/%s' % (handler.prefix, path, filename)
            if not bucket.get_key(keyname):
                handler.upload_sstable(keyname, '%s/%s' % (path, filename), with_index=False)
            else:
                log.info('Not uploading %s/%s, it already exists in this S3 bucket.' % (path, filename))
    return 0

def dl_thread_generator(handler, bucket, local_prefix=''):
    s3_prefix = '%s:' % (handler.prefix)
    file_list = bucket.list(s3_prefix)
    thread_list = []
    for key in file_list:
        local_file = key.name.replace(s3_prefix, local_prefix)
        if not os.path.isdir(os.path.dirname(local_file)):
            os.makedirs(os.path.dirname(local_file))

        t = Thread(target=download_sstables, args=(
                   key, local_file))
        t.setDaemon(True)
        t.start()
        thread_list.append(t)

    for t in thread_list:
        t.join()
    return 0

def download_sstables(key, local_file):
    log.info('Downloading %s' % key.name)

    def progress(sent, total):
        if sent == total:
            log.info('Finished downloading %s' % key.name)
    try:
        key.get_contents_to_filename(local_file, cb=progress)
    except:
        log.error('Error downloading %s\n%s' % (key.name, format_exc()))

def main():
    try:
        conf = {}
        conf['aws_key'] = config.get('tablesnap', 'aws_key')
        conf['aws_secret'] = config.get('tablesnap', 'aws_secret')
        conf['recursive'] = config.get('tablesnap', 'recursive')
        conf['auto_add'] = config.get('tablesnap', 'auto_add')
        conf['args'] = shlex.split(config.get('tablesnap', 'args'))
    except:
        pass

    parser = OptionParser(usage='%prog [options] <bucket> <path> [...]')
    parser.add_option('-k', '--aws-key', dest='aws_key', default=None)
    parser.add_option('-s', '--aws-secret', dest='aws_secret', default=None)
    parser.add_option('-r', '--recursive', action='store_true', dest='recursive', default=False,
        help='Recursively watch the given path(s)s for new SSTables')
    parser.add_option('-a', '--auto-add', action='store_true', dest='auto_add', default=False,
        help='Automatically start watching new subdirectories within path(s)')
    parser.add_option('-B', '--backup', action='store_true', dest='backup',
        help='Backup existing SSTables to S3 if they\'re not already there')
    parser.add_option('-D', '--download', action='store_true', dest='download',
        help='Download existing SSTables on S3 to this EC2 instance')
    options, args = parser.parse_args()

    options.aws_key = conf['aws_key'] if 'aws_key' in conf else options.aws_key
    options.aws_secret = conf['aws_secret'] if 'aws_secret' in conf else options.aws_secret
    options.recursive = conf['recursive'] if 'recursive' in conf else options.recursive
    options.auto_add = conf['auto_add'] if 'auto_add' in conf else options.auto_add
    args = conf['args'] if 'args' in conf else args

    if len(args) < 2:
        parser.print_help()
        return -1

    bucket = args[0]
    paths = args[1:]

    s3 = boto.connect_s3(options.aws_key, options.aws_secret)

    if not s3.lookup(bucket):
        s3.create_bucket(bucket)

    bucket = s3.get_bucket(bucket)
    handler = UploadHandler(bucket=bucket)

    if options.backup:
        return backup_files(handler, bucket, paths)

    if options.download:
        return dl_thread_generator(handler, bucket, paths[0])

    wm = pyinotify.WatchManager()
    notifier = pyinotify.Notifier(wm, handler)
    for path in paths:
        ret = wm.add_watch(path, pyinotify.ALL_EVENTS, rec=options.recursive, auto_add=options.auto_add)
        if ret[path] == -1:
            log.critical('add_watch failed for %s, bailing out!' % path)
            return 1
    notifier.loop()

if __name__ == '__main__':
    sys.exit(main())
